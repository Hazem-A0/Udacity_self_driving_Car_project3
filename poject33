import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.model_selection import train_test_split
from torchvision import transforms
import pandas as pd
import numpy as np
from PIL import Image
import cv2
import os
import matplotlib.pyplot as plt

class SelfDrivingModel(nn.Module):
    def __init__(self):
        super(SelfDrivingModel, self).__init__()
        # Define your neural network layers here
        self.conv1 = nn.Conv2d(3, 24, kernel_size=(5,5), stride=(2,2))
        self.conv2 = nn.Conv2d(24, 36, kernel_size=(5,5), stride=(2,2))
        self.conv3 = nn.Conv2d(36, 48, kernel_size=(5,5), stride=(2,2))
        self.conv4 = nn.Conv2d(48, 64, kernel_size=(3,3))
        self.conv5 = nn.Conv2d(64, 64, kernel_size=(3,3))
        
        # MaxPooling layers
        self.pool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))
        self.pool3 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))

        # Fully connected layers
        self.fc1 = nn.Linear(64*1*18, 100)
        self.fc2 = nn.Linear(100, 50)
        self.fc3 = nn.Linear(50, 10)
        self.fc4 = nn.Linear(10, 1)

    def forward(self, x):
        # Forward pass through convolutional layers
        x = torch.relu(self.conv1(x))
        x = self.pool1(x)
        x = torch.relu(self.conv2(x))
        x = self.pool2(x)
        x = torch.relu(self.conv3(x))
        x = self.pool3(x)
        x = torch.relu(self.conv4(x))
        x = torch.relu(self.conv5(x))
        
        # Flatten the output
        x = x.view(x.size(0), -1)
        
        # Forward pass through fully connected layers
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = torch.relu(self.fc3(x))
        x = self.fc4(x)  # Linear output (steering angle)
        
        return x
    
    def load_data(self):
        # Define the desired column names
        csv_file_path = r'C:\Users\hazem\OneDrive\Desktop\simulator\simulator-windows-64\training data\driving_log.csv'

        column_names = ['center', 'left', 'right', 'steering', 'throttle', 'reverse', 'speed']

        # Load the CSV file into a Pandas DataFrame with the specified column names
        data = pd.read_csv(csv_file_path, names=column_names)

        def read_img(path):
                img = Image.open(path.strip())
                return np.asarray(img)

        # Replace path strings with actual images and convert them to PyTorch tensors
        center_images = torch.from_numpy(np.stack(data['center'].apply(lambda path: read_img(path.strip()))))
        left_images = torch.from_numpy(np.stack(data['left'].apply(lambda path: read_img(path.strip()))))
        right_images = torch.from_numpy(np.stack(data['right'].apply(lambda path: read_img(path.strip()))))
        
        #input data is images from the center camera, left camera, and right camera
        self.x = [center_images, left_images, right_images]
        # Output data is steering command ,throttle
        self.y = data[['steering', 'throttle']][:2133].values
       
 
    def split_data(self):
        train_ratio = 0.8  # 80% for training
        test_ratio = 0.2  # 20% for testing

        num_samples = self.x[0].shape[0]  # Assuming all images have the same dimensions
        num_train = int(train_ratio * num_samples)

        # Split the data into training and test sets
        self.x_train = [x[:num_train] for x in self.x]
        self.y_train = self.y[:num_train]

        self.x_test = [x[num_train:] for x in self.x]
        self.y_test = self.y[num_train:]

    def print_data(self):
        #Check if X and y are equal in length
        print("x_train shape:", [x.shape for x in model.x_train])
        print("y_train shape:", model.y_train.shape)
        print("x_test shapes:", [x.shape for x in model.x_test])
        print("y_test shape:", model.y_test.shape)

    def train(self):
        # Define hyperparameters
        batch_size=1
        num_epochs=10
        learning_rate=0.01

        # Prepare data loaders
        train_dataset = TensorDataset(self.x_train, torch.Tensor(self.y_train))
        test_dataset = TensorDataset(self.x_test, torch.Tensor(self.y_test))
        
        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=batch_size)

        # Define loss function and optimizer
        criterion = nn.MSELoss()
        optimizer = optim.Adam(self.parameters(), lr=learning_rate)

        # Move model to GPU if available
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(device)

        # Training loop
        for epoch in range(num_epochs):
            train_loss = 0.0

            for batch_x, batch_y in train_loader:
                batch_x, batch_y = batch_x.to(device), batch_y.to(device)

                # Zero the parameter gradients
                optimizer.zero_grad()

                # Forward pass
                outputs = self(batch_x)

                # Calculate the loss
                loss = criterion(outputs, batch_y)

                # Backpropagation and optimization
                loss.backward()
                optimizer.step()

                train_loss += loss.item()

            # Calculate and print the average training loss for the epoch
            avg_train_loss = train_loss / len(train_loader)
            print(f'Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}')

            # Validation
            self.eval()  # Set the model in evaluation mode
            val_loss = 0.0

            with torch.no_grad():
                for batch_x, batch_y in test_loader:
                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)
                    outputs = self(batch_x)
                    loss = criterion(outputs, batch_y)
                    val_loss += loss.item()

                # Calculate and print the average validation loss for the epoch
                avg_val_loss = val_loss / len(test_loader)
                print(f'Epoch [{epoch + 1}/{num_epochs}] - Validation Loss: {avg_val_loss:.4f}')

        print('Training completed.')
        
    
if __name__== '__main__':
    model = SelfDrivingModel()
    model.load_data()
    model.split_data()
    #model.print_data()
    model.train()
